#reader(lib"read.ss""wxme")WXME0108 ## 
#|
   This file uses the GRacket editor format.
   Open this file in DrRacket version 7.0 or later to read it.

   Most likely, it was created by saving a program in DrRacket,
   and it probably contains a program with non-text elements
   (such as images or comment boxes).

            http://racket-lang.org/
|#
 33 7 #"wxtext\0"
3 1 6 #"wxtab\0"
1 1 8 #"wximage\0"
2 0 8 #"wxmedia\0"
4 1 34 #"(lib \"syntax-browser.ss\" \"mrlib\")\0"
1 0 36 #"(lib \"cache-image-snip.ss\" \"mrlib\")\0"
1 0 68
(
 #"((lib \"image-core.ss\" \"mrlib\") (lib \"image-core-wxme.rkt\" \"mr"
 #"lib\"))\0"
) 1 0 16 #"drscheme:number\0"
3 0 44 #"(lib \"number-snip.ss\" \"drscheme\" \"private\")\0"
1 0 36 #"(lib \"comment-snip.ss\" \"framework\")\0"
1 0 93
(
 #"((lib \"collapsed-snipclass.ss\" \"framework\") (lib \"collapsed-sni"
 #"pclass-wxme.ss\" \"framework\"))\0"
) 0 0 43 #"(lib \"collapsed-snipclass.ss\" \"framework\")\0"
0 0 19 #"drscheme:sexp-snip\0"
0 0 29 #"drscheme:bindings-snipclass%\0"
1 0 101
(
 #"((lib \"ellipsis-snip.rkt\" \"drracket\" \"private\") (lib \"ellipsi"
 #"s-snip-wxme.rkt\" \"drracket\" \"private\"))\0"
) 2 0 88
(
 #"((lib \"pict-snip.rkt\" \"drracket\" \"private\") (lib \"pict-snip.r"
 #"kt\" \"drracket\" \"private\"))\0"
) 0 0 55
#"((lib \"snip.rkt\" \"pict\") (lib \"snip-wxme.rkt\" \"pict\"))\0"
1 0 34 #"(lib \"bullet-snip.rkt\" \"browser\")\0"
0 0 25 #"(lib \"matrix.ss\" \"htdp\")\0"
1 0 22 #"drscheme:lambda-snip%\0"
1 0 29 #"drclickable-string-snipclass\0"
0 0 26 #"drracket:spacer-snipclass\0"
0 0 57
#"(lib \"hrule-snip.rkt\" \"macro-debugger\" \"syntax-browser\")\0"
1 0 26 #"drscheme:pict-value-snip%\0"
0 0 45 #"(lib \"image-snipr.ss\" \"slideshow\" \"private\")\0"
1 0 38 #"(lib \"pict-snipclass.ss\" \"slideshow\")\0"
2 0 55 #"(lib \"vertical-separator-snip.ss\" \"stepper\" \"private\")\0"
1 0 18 #"drscheme:xml-snip\0"
1 0 31 #"(lib \"xml-snipclass.ss\" \"xml\")\0"
1 0 21 #"drscheme:scheme-snip\0"
2 0 34 #"(lib \"scheme-snipclass.ss\" \"xml\")\0"
1 0 10 #"text-box%\0"
1 0 32 #"(lib \"text-snipclass.ss\" \"xml\")\0"
1 0 1 6 #"wxloc\0"
          0 0 55 0 1 #"\0"
0 75 1 #"\0"
0 10 90 -1 90 -1 3 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 255 255 255 1 -1 0 9
#"Standard\0"
0 75 12 #"Courier New\0"
0 12 90 -1 90 -1 3 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 255 255 255 1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 -1 -1 2 24
#"framework:default-color\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1 1 1 150 0 150 0 0 0 -1 -1 2 15
#"text:ports out\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 150 0 150 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1.0 0 -1 -1 93 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 255 0 0 0 0 0 -1
-1 2 15 #"text:ports err\0"
0 -1 1 #"\0"
1 0 -1 -1 93 -1 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 175 0 0 0 -1 -1 2 17
#"text:ports value\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 175 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1.0 0 92 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 34 139 34 0 0 0 -1
-1 2 27 #"Matching Parenthesis Style\0"
0 -1 1 #"\0"
1.0 0 92 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 34 139 34 0 0 0 -1
-1 2 1 #"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 38 38 128 0 0 0 -1 -1 2 37
#"framework:syntax-color:scheme:symbol\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 38 38 128 0 0 0 -1 -1 2 38
#"framework:syntax-color:scheme:keyword\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 38 38 128 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 194 116 31 0 0 0 -1 -1 2
38 #"framework:syntax-color:scheme:comment\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 194 116 31 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 41 128 38 0 0 0 -1 -1 2 37
#"framework:syntax-color:scheme:string\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 41 128 38 0 0 0 -1 -1 2 35
#"framework:syntax-color:scheme:text\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 41 128 38 0 0 0 -1 -1 2 39
#"framework:syntax-color:scheme:constant\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 41 128 38 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 132 60 36 0 0 0 -1 -1 2 49
#"framework:syntax-color:scheme:hash-colon-keyword\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 132 60 36 0 0 0 -1 -1 2 42
#"framework:syntax-color:scheme:parenthesis\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 132 60 36 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 36
#"framework:syntax-color:scheme:error\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 36
#"framework:syntax-color:scheme:other\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 16
#"Misspelled Text\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 81 112 203 0 0 0 -1 -1 2
38 #"drracket:check-syntax:lexically-bound\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 81 112 203 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 178 34 34 0 0 0 -1 -1 2 28
#"drracket:check-syntax:set!d\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 178 34 34 0 0 0 -1 -1 2 37
#"drracket:check-syntax:unused-require\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 36
#"drracket:check-syntax:free-variable\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 68 0 203 0 0 0 -1 -1 2 31
#"drracket:check-syntax:imported\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 68 0 203 0 0 0 -1 -1 2 47
#"drracket:check-syntax:my-obligation-style-pref\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 178 34 34 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 116 0 0 0 0 -1 -1 2 50
#"drracket:check-syntax:their-obligation-style-pref\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 116 0 0 0 0 -1 -1 2 48
#"drracket:check-syntax:unk-obligation-style-pref\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 139 142 28 0 0 0 -1 -1 2
49 #"drracket:check-syntax:both-obligation-style-pref\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 139 142 28 0 0 0 -1 -1 2
26 #"plt:htdp:test-coverage-on\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 1 0 0 0 0 0 0 255 165 0 0 0 0 -1 -1 2 27
#"plt:htdp:test-coverage-off\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 1 0 0 0 0 0 0 255 165 0 0 0 0 -1 -1 4 1
#"\0"
0 70 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 1.0 1.0 1.0 1.0 1.0 1.0 0 0 0 0 0 0
-1 -1 4 4 #"XML\0"
0 70 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 1.0 1.0 1.0 1.0 1.0 1.0 0 0 0 0 0 0
-1 -1 2 37 #"plt:module-language:test-coverage-on\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 38
#"plt:module-language:test-coverage-off\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 1 0 0 0 0 0 0 255 165 0 0 0 0 -1 -1 4 1
#"\0"
0 71 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 1.0 1.0 1.0 1.0 1.0 1.0 0 0 0 0 0 0
-1 -1 4 1 #"\0"
0 -1 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 1 0 0 0 0 0 0 0 0 1.0 1.0 1.0 0 0 255 0 0 0 -1
-1 4 1 #"\0"
0 71 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 1 0 0 0 0 0 0 0 0 1.0 1.0 1.0 0 0 255 0 0 0 -1
-1 4 1 #"\0"
0 71 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 0 100 0 0 0 0 -1
-1           0 516 0 28 3 12 #"#lang racket"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 7 #"require"
0 0 24 3 1 #" "
0 0 14 3 12 #"data-science"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 7 #"require"
0 0 24 3 1 #" "
0 0 14 3 4 #"plot"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 7 #"require"
0 0 24 3 1 #" "
0 0 14 3 4 #"math"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 7 #"require"
0 0 24 3 1 #" "
0 0 14 3 4 #"json"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 7 #"require"
0 0 24 3 1 #" "
0 0 14 3 7 #"srfi/19"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 7 #"require"
0 0 24 3 1 #" "
0 0 14 3 13 #"racket/stream"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 131
(
 #";;; This function reads line-oriented JSON (as output by massmine),a"
 #"nd packages it into an array. For very large data sets, loading"
) 0 0 24 29 1 #"\n"
0 0 17 3 102
(
 #";;; everything into memory like this is heavy handed. For data this "
 #"small,working in memory is simpler"
) 0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 22 #"json-lines->json-array"
0 0 24 3 1 #" "
0 0 23 3 6 #"#:head"
0 0 24 3 2 #" ["
0 0 14 3 4 #"head"
0 0 24 3 1 #" "
0 0 21 3 2 #"#f"
0 0 24 3 2 #"])"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 15 3 3 #"let"
0 0 24 3 1 #" "
0 0 14 3 4 #"loop"
0 0 24 3 3 #" (["
0 0 14 3 3 #"num"
0 0 24 3 1 #" "
0 0 21 3 1 #"0"
0 0 24 3 1 #"]"
0 0 24 29 1 #"\n"
0 0 24 3 14 #"             ["
0 0 14 3 10 #"json-array"
0 0 24 3 1 #" "
0 0 21 3 1 #"'"
0 0 24 3 3 #"()]"
0 0 24 29 1 #"\n"
0 0 24 3 14 #"             ["
0 0 14 3 6 #"record"
0 0 24 3 2 #" ("
0 0 14 3 9 #"read-json"
0 0 24 3 2 #" ("
0 0 14 3 18 #"current-input-port"
0 0 24 3 4 #"))])"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"    ("
0 0 14 3 2 #"if"
0 0 24 3 2 #" ("
0 0 14 3 2 #"or"
0 0 24 3 2 #" ("
0 0 14 3 11 #"eof-object?"
0 0 24 3 1 #" "
0 0 14 3 6 #"record"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 13 #"            ("
0 0 14 3 3 #"and"
0 0 24 3 1 #" "
0 0 14 3 4 #"head"
0 0 24 3 2 #" ("
0 0 14 3 2 #">="
0 0 24 3 1 #" "
0 0 14 3 3 #"num"
0 0 24 3 1 #" "
0 0 14 3 4 #"head"
0 0 24 3 3 #")))"
0 0 24 29 1 #"\n"
0 0 24 3 9 #"        ("
0 0 14 3 14 #"jsexpr->string"
0 0 24 3 1 #" "
0 0 14 3 10 #"json-array"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 9 #"        ("
0 0 14 3 4 #"loop"
0 0 24 3 2 #" ("
0 0 14 3 4 #"add1"
0 0 24 3 1 #" "
0 0 14 3 3 #"num"
0 0 24 3 3 #") ("
0 0 14 3 4 #"cons"
0 0 24 3 1 #" "
0 0 14 3 6 #"record"
0 0 24 3 1 #" "
0 0 14 3 10 #"json-array"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 15 #"              ("
0 0 14 3 9 #"read-json"
0 0 24 3 2 #" ("
0 0 14 3 18 #"current-input-port"
0 0 24 3 6 #"))))))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 70
(
 #";;; Normalize case, remove URLs, remove punctuation, and remove spac"
 #"es"
) 0 0 24 29 1 #"\n"
0 0 17 3 70
(
 #";;; from each tweet. This function takes a list of words and returns"
 #" a"
) 0 0 24 29 1 #"\n"
0 0 17 3 49 #";;; preprocessed subset of words/tokens as a list"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 15 #"preprocess-text"
0 0 24 3 1 #" "
0 0 14 3 3 #"lst"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 14 3 3 #"map"
0 0 24 3 2 #" ("
0 0 15 3 2 #"\316\273"
0 0 24 3 2 #" ("
0 0 14 3 1 #"x"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 10 #"         ("
0 0 14 3 23 #"string-normalize-spaces"
0 0 24 29 1 #"\n"
0 0 24 3 11 #"          ("
0 0 14 3 18 #"remove-punctuation"
0 0 24 29 1 #"\n"
0 0 24 3 12 #"           ("
0 0 14 3 11 #"remove-urls"
0 0 24 29 1 #"\n"
0 0 24 3 13 #"            ("
0 0 14 3 15 #"string-downcase"
0 0 24 3 1 #" "
0 0 14 3 1 #"x"
0 0 24 3 4 #"))) "
0 0 23 3 10 #"#:websafe?"
0 0 24 3 1 #" "
0 0 21 3 2 #"#t"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 3 7 #"       "
0 0 14 3 3 #"lst"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 62
#";;; Read in the entire tweet database Daily Monitor Timeline  "
0 0 17 3 13 #"(3242) TWEETS"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 1 #" "
0 0 14 3 6 #"tweets"
0 0 24 3 2 #" ("
0 0 14 3 14 #"string->jsexpr"
0 0 24 29 1 #"\n"
0 0 24 3 17 #"                ("
0 0 15 3 20 #"with-input-from-file"
0 0 24 3 1 #" "
0 0 19 3 20 #"\"daily_monitor.json\""
0 0 24 3 2 #" ("
0 0 15 3 2 #"\316\273"
0 0 24 3 5 #" () ("
0 0 14 3 22 #"json-lines->json-array"
0 0 24 3 5 #")))))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 91
(
 #";;t is a list of lists of strings. Tail recursion is used to extract"
 #" each string and append"
) 0 0 24 29 1 #"\n"
0 0 17 3 28 #";; it into one large string."
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 1 #" "
0 0 14 3 11 #"list-string"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 15 3 3 #"let"
0 0 24 3 3 #" (["
0 0 14 3 3 #"tmp"
0 0 24 3 2 #" ("
0 0 14 3 3 #"map"
0 0 24 3 2 #" ("
0 0 15 3 2 #"\316\273"
0 0 24 3 2 #" ("
0 0 14 3 1 #"x"
0 0 24 3 3 #") ("
0 0 14 3 4 #"list"
0 0 24 3 2 #" ("
0 0 14 3 8 #"hash-ref"
0 0 24 3 1 #" "
0 0 14 3 1 #"x"
0 0 24 3 1 #" "
0 0 21 3 1 #"'"
0 0 14 3 9 #"full_text"
0 0 24 3 4 #"))) "
0 0 14 3 6 #"tweets"
0 0 24 3 4 #")]) "
0 0 17 3 25 #";; improve to use streams"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"    ("
0 0 14 3 6 #"filter"
0 0 24 3 2 #" ("
0 0 15 3 2 #"\316\273"
0 0 24 3 2 #" ("
0 0 14 3 1 #"x"
0 0 24 3 3 #") ("
0 0 14 3 3 #"not"
0 0 24 3 2 #" ("
0 0 14 3 14 #"string-prefix?"
0 0 24 3 2 #" ("
0 0 14 3 5 #"first"
0 0 24 3 1 #" "
0 0 14 3 1 #"x"
0 0 24 3 2 #") "
0 0 19 3 4 #"\"RT\""
0 0 24 3 4 #"))) "
0 0 14 3 3 #"tmp"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 6 #"    ))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 74
(
 #"; Joining tweets and arranging tweets to their systematic flow in an"
 #"d out."
) 0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 1 #" "
0 0 14 3 13 #"joined-tweets"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"    ("
0 0 15 3 5 #"local"
0 0 24 3 1 #"["
0 0 24 29 1 #"\n"
0 0 24 3 12 #"           ("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 7 #"joined1"
0 0 24 3 1 #" "
0 0 14 3 6 #"tlist1"
0 0 24 3 1 #" "
0 0 14 3 3 #"acc"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 14 #"             ("
0 0 15 3 4 #"cond"
0 0 24 3 3 #" [("
0 0 14 3 6 #"empty?"
0 0 24 3 1 #" "
0 0 14 3 6 #"tlist1"
0 0 24 3 2 #") "
0 0 14 3 3 #"acc"
0 0 24 3 1 #"]"
0 0 24 29 1 #"\n"
0 0 24 3 20 #"                   ["
0 0 14 3 4 #"else"
0 0 24 3 2 #" ("
0 0 14 3 7 #"joined1"
0 0 24 3 2 #" ("
0 0 14 3 4 #"rest"
0 0 24 3 1 #" "
0 0 14 3 6 #"tlist1"
0 0 24 3 3 #") ("
0 0 14 3 11 #"string-join"
0 0 24 3 2 #" ("
0 0 14 3 4 #"list"
0 0 24 3 1 #" "
0 0 14 3 3 #"acc"
0 0 24 3 1 #" "
0 0 19 3 5 #"\"\\n \""
0 0 24 3 2 #" ("
0 0 14 3 5 #"first"
0 0 24 3 1 #"("
0 0 14 3 5 #"first"
0 0 24 3 1 #" "
0 0 14 3 6 #"tlist1"
0 0 24 3 6 #")))))]"
0 0 24 29 1 #"\n"
0 0 24 3 20 #"                   )"
0 0 24 29 1 #"\n"
0 0 24 3 14 #"             )"
0 0 24 29 1 #"\n"
0 0 24 3 13 #"           ]("
0 0 14 3 7 #"joined1"
0 0 24 3 1 #" "
0 0 14 3 11 #"list-string"
0 0 24 3 1 #" "
0 0 19 3 2 #"\"\""
0 0 24 3 4 #")) )"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 64
#";;; To begin our sentiment analysis, we extract each unique word"
0 0 24 29 1 #"\n"
0 0 17 3 55 #";;; and the number of times it occurred in the document"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 1 #" "
0 0 14 3 5 #"words"
0 0 24 3 2 #" ("
0 0 14 3 16 #"document->tokens"
0 0 24 3 1 #" "
0 0 14 3 13 #"joined-tweets"
0 0 24 3 1 #" "
0 0 23 3 7 #"#:sort?"
0 0 24 3 1 #" "
0 0 21 3 2 #"#t"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 68
#";;; Using the nrc lexicon, we can label each (non stop-word) with an"
0 0 24 29 1 #"\n"
0 0 17 3 21 #";;; emotional label. "
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 1 #" "
0 0 14 3 9 #"sentiment"
0 0 24 3 2 #" ("
0 0 14 3 15 #"list->sentiment"
0 0 24 3 1 #" "
0 0 14 3 5 #"words"
0 0 24 3 1 #" "
0 0 23 3 9 #"#:lexicon"
0 0 24 3 1 #" "
0 0 21 3 1 #"'"
0 0 14 3 3 #"nrc"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 14 3 4 #"take"
0 0 24 3 1 #" "
0 0 14 3 9 #"sentiment"
0 0 24 3 1 #" "
0 0 21 3 1 #"5"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 75
(
 #";;; sentiment, created above, consists of a list of triplets of the "
 #"pattern"
) 0 0 24 29 1 #"\n"
0 0 17 3 80
(
 #";;; (token sentiment freq) for each token in the document. Many word"
 #"s will have "
) 0 0 24 29 1 #"\n"
0 0 17 3 79
(
 #";;; the same sentiment label, so we aggregrate (by summing) across s"
 #"uch tokens."
) 0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 14 3 9 #"aggregate"
0 0 24 3 1 #" "
0 0 14 3 3 #"sum"
0 0 24 3 2 #" ("
0 0 14 3 1 #"$"
0 0 24 3 1 #" "
0 0 14 3 9 #"sentiment"
0 0 24 3 1 #" "
0 0 21 3 1 #"'"
0 0 14 3 9 #"sentiment"
0 0 24 3 3 #") ("
0 0 14 3 1 #"$"
0 0 24 3 1 #" "
0 0 14 3 9 #"sentiment"
0 0 24 3 1 #" "
0 0 21 3 1 #"'"
0 0 14 3 4 #"freq"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 78
(
 #";;; Better yet, we can visualize this result as a barplot (discrete-"
 #"histogram)"
) 0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 3 #"let"
0 0 24 3 3 #" (["
0 0 14 3 6 #"counts"
0 0 24 3 2 #" ("
0 0 14 3 9 #"aggregate"
0 0 24 3 1 #" "
0 0 14 3 3 #"sum"
0 0 24 3 2 #" ("
0 0 14 3 1 #"$"
0 0 24 3 1 #" "
0 0 14 3 9 #"sentiment"
0 0 24 3 1 #" "
0 0 21 3 1 #"'"
0 0 14 3 9 #"sentiment"
0 0 24 3 3 #") ("
0 0 14 3 1 #"$"
0 0 24 3 1 #" "
0 0 14 3 9 #"sentiment"
0 0 24 3 1 #" "
0 0 21 3 1 #"'"
0 0 14 3 4 #"freq"
0 0 24 3 4 #"))])"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 15 3 12 #"parameterize"
0 0 24 3 3 #" (("
0 0 14 3 10 #"plot-width"
0 0 24 3 1 #" "
0 0 21 3 3 #"800"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"    ("
0 0 14 3 4 #"plot"
0 0 24 3 2 #" ("
0 0 14 3 4 #"list"
0 0 24 29 1 #"\n"
0 1 24 65 1 #"\t"
0 0 24 3 4 #"   ("
0 0 14 3 9 #"tick-grid"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 1 24 65 1 #"\t"
0 0 24 3 4 #"   ("
0 0 14 3 18 #"discrete-histogram"
0 0 24 29 1 #"\n"
0 1 24 65 1 #"\t"
0 0 24 3 5 #"    ("
0 0 14 3 4 #"sort"
0 0 24 3 1 #" "
0 0 14 3 6 #"counts"
0 0 24 3 2 #" ("
0 0 15 3 2 #"\316\273"
0 0 24 3 2 #" ("
0 0 14 3 1 #"x"
0 0 24 3 1 #" "
0 0 14 3 1 #"y"
0 0 24 3 3 #") ("
0 0 14 3 1 #">"
0 0 24 3 2 #" ("
0 0 14 3 6 #"second"
0 0 24 3 1 #" "
0 0 14 3 1 #"x"
0 0 24 3 3 #") ("
0 0 14 3 6 #"second"
0 0 24 3 1 #" "
0 0 14 3 1 #"y"
0 0 24 3 4 #"))))"
0 0 24 29 1 #"\n"
0 1 24 65 1 #"\t"
0 0 24 3 4 #"    "
0 0 23 3 7 #"#:color"
0 0 24 3 1 #" "
0 0 19 3 11 #"\"OrangeRed\""
0 0 24 29 1 #"\n"
0 1 24 65 1 #"\t"
0 0 24 3 4 #"    "
0 0 23 3 12 #"#:line-color"
0 0 24 3 1 #" "
0 0 19 3 15 #"\"LightSeaGreen\""
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 3 12 #"            "
0 0 23 3 9 #"#:x-label"
0 0 24 3 1 #" "
0 0 19 3 6 #"\"Mood\""
0 0 24 29 1 #"\n"
0 1 24 65 1 #"\t"
0 0 24 3 4 #"    "
0 0 23 3 9 #"#:y-label"
0 0 24 3 1 #" "
0 0 19 3 18 #"\"Number Of Tweets\""
0 0 24 29 1 #"\n"
0 0 24 3 12 #"            "
0 0 23 3 7 #"#:width"
0 0 24 3 1 #" "
0 0 21 3 3 #"900"
0 0 24 29 1 #"\n"
0 0 24 3 1 #" "
0 1 24 65 1 #"\t"
0 0 24 3 4 #"    "
0 0 23 3 8 #"#:height"
0 0 24 3 1 #" "
0 0 21 3 3 #"500"
0 0 24 29 1 #"\n"
0 0 24 3 12 #"            "
0 0 23 3 7 #"#:title"
0 0 24 3 1 #" "
0 0 19 3 68
(
 #"\"ANALYSE THE MOOD OF TWEETS OF DAILY MONITOR TIMELINE (3242) TWEETS"
 #"\""
) 0 0 24 3 1 #" "
0 0 24 29 1 #"\n"
0 0 24 3 13 #"          )))"
0           0
